{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import csv\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagename =  ['data\\\\0\\\\0.jpg' 'data\\\\0\\\\1.jpg' 'data\\\\0\\\\10.jpg' 'data\\\\0\\\\11.jpg'\n",
      " 'data\\\\0\\\\12.jpg' 'data\\\\0\\\\13.jpg' 'data\\\\0\\\\14.jpg' 'data\\\\0\\\\15.jpg'\n",
      " 'data\\\\0\\\\16.jpg' 'data\\\\0\\\\17.jpg']\n",
      "labelname =  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "imagename =  ['testdata\\\\0\\\\0.jpg' 'testdata\\\\0\\\\1.jpg' 'testdata\\\\0\\\\2.jpg'\n",
      " 'testdata\\\\0\\\\3.jpg' 'testdata\\\\0\\\\4.jpg' 'testdata\\\\0\\\\5.jpg'\n",
      " 'testdata\\\\0\\\\6.jpg' 'testdata\\\\0\\\\7.jpg' 'testdata\\\\0\\\\8.jpg'\n",
      " 'testdata\\\\0\\\\9.jpg']\n",
      "labelname =  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------------------------------------------------\n",
      "x_train: (1000, 32, 32, 3) y_train: (1000,)\n",
      "dataset <BatchDataset shapes: ((None, 100, 100, 3), (None,)), types: (tf.float32, tf.int32)>\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            multiple                  2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           multiple                  18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           multiple                  36928     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  20480512  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  65664     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 20,605,322\n",
      "Trainable params: 20,605,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "    100/Unknown - 24s 243ms/step - loss: 2.3009 - accuracy: 0.0990WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.3009 - accuracy: 0.0990\n",
      "Epoch 2/5\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.2962 - accuracy: 0.1131WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 2.2962 - accuracy: 0.1140\n",
      "Epoch 3/5\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.2903 - accuracy: 0.1253WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 2.2903 - accuracy: 0.1250\n",
      "Epoch 4/5\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.2840 - accuracy: 0.1545WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 2.2840 - accuracy: 0.1540\n",
      "Epoch 5/5\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.2770 - accuracy: 0.1535WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 2.2770 - accuracy: 0.1550\n",
      "保存模型权重成功\n",
      "INFO:tensorflow:Assets written to: model/gestureModel_one\\assets\n",
      "保存模型成功\n"
     ]
    }
   ],
   "source": [
    "def get_image(im):\n",
    "    image = cv.resize(im, (100, 100))\n",
    "    # print(\"image.shape\", len(image))\n",
    "    # gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    # ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)\n",
    "    image2 = image.reshape(-1, 100, 100,  3)\n",
    "    image3 = tf.cast(image2 / 255.0, tf.float32)\n",
    "    return image3\n",
    "\n",
    "\n",
    "def get_roi(frame, x1, x2, y1, y2):\n",
    "    dst = frame[x1:x2, y1:y2]\n",
    "    cv.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), thickness=2)\n",
    "    return dst\n",
    "\n",
    "\n",
    "# 获取图片，存放到对应的列表中，同时贴上标签，存放到label列表中\n",
    "def get_files(file_dir):\n",
    "    # 存放图片类别和标签的列表：第0类\n",
    "    list_0 = []\n",
    "    label_0 = []\n",
    "    # 存放图片类别和标签的列表：第1类\n",
    "    list_1 = []\n",
    "    label_1 = []\n",
    "    # 存放图片类别和标签的列表：第2类\n",
    "    list_2 = []\n",
    "    label_2 = []\n",
    "    # 存放图片类别和标签的列表：第3类\n",
    "    list_3 = []\n",
    "    label_3 = []\n",
    "    # 存放图片类别和标签的列表：第4类\n",
    "    list_4 = []\n",
    "    label_4 = []\n",
    "    # 存放图片类别和标签的列表：第5类\n",
    "    list_5 = []\n",
    "    label_5 = []\n",
    "    # 存放图片类别和标签的列表：第6类\n",
    "    list_6 = []\n",
    "    label_6 = []\n",
    "    # 存放图片类别和标签的列表：第6类\n",
    "    list_7 = []\n",
    "    label_7 = []\n",
    "    # 存放图片类别和标签的列表：第8类\n",
    "    list_8 = []\n",
    "    label_8 = []\n",
    "    # 存放图片类别和标签的列表：第9类\n",
    "    list_9 = []\n",
    "    label_9 = []\n",
    "\n",
    "    for file in os.listdir(file_dir):  # 获得file_dir路径下的全部文件名\n",
    "        # print(file)\n",
    "        # 拼接出图片文件路径\n",
    "        image_file_path = os.path.join(file_dir, file)\n",
    "        for image_name in os.listdir(image_file_path):\n",
    "            # print('image_name',image_name)\n",
    "            # 图片的完整路径\n",
    "            image_name_path = os.path.join(image_file_path, image_name)\n",
    "            # print('image_name_path',image_name_path)\n",
    "            # 将图片存放入对应的列表\n",
    "            if image_file_path[-1:] == '0':\n",
    "                list_0.append(image_name_path)\n",
    "                label_0.append(0)\n",
    "            elif image_file_path[-1:] == '1':\n",
    "                list_1.append(image_name_path)\n",
    "                label_1.append(1)\n",
    "            elif image_file_path[-1:] == '2':\n",
    "                list_2.append(image_name_path)\n",
    "                label_2.append(2)\n",
    "            elif image_file_path[-1:] == '3':\n",
    "                list_3.append(image_name_path)\n",
    "                label_3.append(3)\n",
    "            elif image_file_path[-1:] == '4':\n",
    "                list_3.append(image_name_path)\n",
    "                label_3.append(4)\n",
    "            elif image_file_path[-1:] == '5':\n",
    "                list_3.append(image_name_path)\n",
    "                label_3.append(5)\n",
    "            elif image_file_path[-1:] == '6':\n",
    "                list_3.append(image_name_path)\n",
    "                label_3.append(6)\n",
    "            elif image_file_path[-1:] == '7':\n",
    "                list_3.append(image_name_path)\n",
    "                label_3.append(7)\n",
    "            elif image_file_path[-1:] == '8':\n",
    "                list_3.append(image_name_path)\n",
    "                label_3.append(8)\n",
    "            else:\n",
    "                list_4.append(image_name_path)\n",
    "                label_4.append(9)\n",
    "\n",
    "    # 合并数据\n",
    "    image_list = np.hstack((list_0, list_1, list_2, list_3, list_4, list_5, list_6, list_7, list_8, list_9))\n",
    "    label_list = np.hstack((label_0, label_1, label_2, label_3, label_4, label_5, label_6, label_7, label_8, label_9))\n",
    "    # 利用shuffle打乱数据\n",
    "    print(\"imagename = \", image_list[:10])\n",
    "    print(\"labelname = \", label_list[:10])\n",
    "\n",
    "    temp = np.array([image_list, label_list])\n",
    "    temp = temp.transpose()  # 转置\n",
    "    np.random.shuffle(temp)\n",
    "\n",
    "    # 将所有的image和label转换成list\n",
    "    image_list = list(temp[:, 0])\n",
    "    image_list = [i for i in image_list]\n",
    "    label_list = list(temp[:, 1])\n",
    "    label_list = [int(float(i)) for i in label_list]\n",
    "    # print(image_list)\n",
    "    # print(label_list)\n",
    "    return image_list, label_list\n",
    "\n",
    "\n",
    "def get_tensor(image_list, label_list):\n",
    "    ims = []\n",
    "    for image in image_list:\n",
    "        # 读取路径下的图片\n",
    "        x = tf.io.read_file(image)\n",
    "        # 将路径映射为照片,3通道\n",
    "        x = tf.image.decode_jpeg(x, channels=3)\n",
    "        # 修改图像大小\n",
    "        x = tf.image.resize(x, [32, 32])\n",
    "        # 将图像压入列表中\n",
    "        ims.append(x)\n",
    "    # 将列表转换成tensor类型\n",
    "    img = tf.convert_to_tensor(ims)\n",
    "    y = tf.convert_to_tensor(label_list)\n",
    "    return img, y\n",
    "\n",
    "\n",
    "def train_model(train_data):\n",
    "    # 构建模型\n",
    "    network = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu),\n",
    "        keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "        keras.layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "        keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "        keras.layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(10)])\n",
    "    network.build(input_shape=(None, 100, 100, channels))\n",
    "    network.summary()\n",
    "\n",
    "    network.compile(optimizer=optimizers.SGD(lr=0.001),\n",
    "                    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=['accuracy']\n",
    "                    )\n",
    "    checkpoint_filepath = \"model\"\n",
    "    callbacks = [\n",
    "        # 保存模型的回调函数\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,  # 保存路径\n",
    "                                           save_weights_only=True,\n",
    "                                           verbose=0,\n",
    "                                           save_freq='epoch'),  # 保存频次以周期频次来计算\n",
    "        # 中止训练的回调函数\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)  # 防止过拟合,如果过拟合了之后就终止1_val验证集上loss变高终止观察3个周期\n",
    "    ]\n",
    "    # 只要在model.fit训练模型里面加上 callbacks=callbacks  这个参数,那在训练模型的时候就会按  照我们设计的回调函数来保存模型\n",
    "    # 模型训练\n",
    "    # 看这里看这里！！！network.load_weights('E:\\\\aiFile\\\\model_save\\\\gesture_recognition_model\\\\gestureModel_one.h5')\n",
    "    # print(\"载入已训练权重成功\")\n",
    "    network.fit(train_data, epochs=5, callbacks=callbacks)  # 因为是dataset数据集是个元组自带标签所以不用分x和y了\n",
    "    # network.evaluate(test_data)\n",
    "    network.save_weights('model/gestureModel_one.h5')\n",
    "    print(\"保存模型权重成功\")\n",
    "    tf.saved_model.save(network, 'model/gestureModel_one')\n",
    "    print(\"保存模型成功\")\n",
    "    return network\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=channels)\n",
    "    image = tf.image.resize(image, [100, 100])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    # image = tf.reshape(image,[100*100*3])\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image), label\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # capture = cv.VideoCapture(0)\n",
    "    # x1 = 400\n",
    "    # x2 = 650\n",
    "    # y1 = 50\n",
    "    # y2 = 300\n",
    "    # 训练图片的路径\n",
    "    global channels\n",
    "    channels = 3\n",
    "    # 导入原始训练数据\n",
    "    train_dir = 'data'\n",
    "    # 建立测试图片并指定文件夹的路径\n",
    "    test_dir = 'testdata'\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    # 训练图片与标签\n",
    "    image_list, label_list = get_files(train_dir)\n",
    "    # 测试图片与标签\n",
    "    test_image_list, test_label_list = get_files(test_dir)\n",
    "\n",
    "    x_train, y_train = get_tensor(image_list, label_list)\n",
    "    x_test, y_test = get_tensor(test_image_list, test_label_list)\n",
    "\n",
    "    print('--------------------------------------------------------')\n",
    "    print('x_train:', x_train.shape, 'y_train:', y_train.shape)\n",
    "\n",
    "    db_train = tf.data.Dataset.from_tensor_slices((image_list, y_train))\n",
    "    # # shuffle:打乱数据,map:数据预处理，batch:一次取喂入10样本训练\n",
    "    db_train = db_train.shuffle(1000).map(load_and_preprocess_image).batch(10)\n",
    "    #\n",
    "    # # 载入训练数据集\n",
    "    db_test = tf.data.Dataset.from_tensor_slices((test_image_list, y_test))\n",
    "    # # # shuffle:打乱数据,map:数据预处理，batch:一次取喂入10样本训练\n",
    "    db_test = db_test.shuffle(1000).map(load_and_preprocess_image).batch(10)\n",
    "    print(\"训练数据\", db_train)\n",
    "    network = train_model(db_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
